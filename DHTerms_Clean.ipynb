{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac658ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce0326",
   "metadata": {},
   "source": [
    "# Digital health terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f7962",
   "metadata": {},
   "source": [
    "## ClinicalTrials.gov: June 29, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd312c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DHTermSearch import query_ctgov_api\n",
    "\n",
    "### Retrieve DTx clinical trials that contain \"digital health\"\n",
    "queries = [\"digital health\"]\n",
    "\n",
    "fields_list = {\"Metadata\": [\"NCTId\", \"OverallStatus\", \"StartDate\",\n",
    "                            \"BriefSummary\", \"InterventionName\", \"InterventionDescription\", \"BriefTitle\",\n",
    "                             \"Keyword\", \"DetailedDescription\", \"OfficialTitle\", \"EligibilityCriteria\"]} \n",
    "    \n",
    "# get clinical trials that match specific search fields\n",
    "search_fields = fields_list[\"Metadata\"]\n",
    "\n",
    "full_query_df = pd.DataFrame(columns=[\"NCTId\"])\n",
    "for q in queries:\n",
    "    print(q)\n",
    "    clinical_df = pd.DataFrame(columns=[\"NCTId\"])\n",
    "    for key in fields_list.keys(): \n",
    "        curr_df = query_ctgov_api(q, fields_list[key], search_field=search_fields)\n",
    "        clinical_df = clinical_df.merge(curr_df, how=\"outer\", left_on=\"NCTId\", right_on=\"NCTId\")\n",
    "    clinical_df[\"query\"]=q\n",
    "    print(len(clinical_df))\n",
    "    full_query_df = pd.concat([clinical_df, full_query_df])\n",
    "\n",
    "full_query_df = full_query_df.drop_duplicates(subset=[\"NCTId\"])\n",
    "print(len(full_query_df))\n",
    "\n",
    "# Remove stopwords using NLTK English stopwords, as well as removing special characters and numbers\n",
    "# Only words with >3 characters were considered\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords = all_stopwords + [\"patient\", \"subject\", \"participant\", \"studies\", \"study\", \"years\", \"months\",\n",
    "                  \"individual\", \"eg\",  \"weeks\", \"diagnosis\", \"participation\", \"participate\", \"patients\", \"participants\"]\n",
    "\n",
    "text = \" \".join(list(full_query_df.apply(' '.join, axis=1)))\n",
    "text = text.lower()\n",
    "text = re.sub('inclusion criteria', ' ', text)\n",
    "text = re.sub('exclusion criteria', ' ', text)\n",
    "text = re.sub('[\\n\\t\\-,]', ' ', text)\n",
    "text = re.sub('[^A-Za-z ]+', ' ', text)\n",
    "text = re.sub('[ ]+', ' ', text)\n",
    "text = text.split(\" \")\n",
    "text = [t for t in text if t not in all_stopwords if len(t)>3]\n",
    "\n",
    "# Top 1000 1,2, and 3-grams present in clinical trial descriptions, titles, eligibility criteria,\n",
    "# For 1-grams, only specialty names were considered\n",
    "terms_df = pd.DataFrame()\n",
    "\n",
    "for i in range(1,4):\n",
    "    ngram_counts = Counter(ngrams(text, i))\n",
    "    ngram_list = [(\" \".join(i), ngram_counts[i]) for i in ngram_counts if ngram_counts[i]]\n",
    "    ngram_df = pd.DataFrame(ngram_list, columns = [\"term\", \"count\"])\n",
    "    ngram_df = ngram_df.sort_values(\"count\", ascending=False)\n",
    "    ngram_df = ngram_df[ngram_df[\"count\"]>49]\n",
    "    terms_df = pd.concat([terms_df, ngram_df])\n",
    "    \n",
    "# Last run June 29, 2023\n",
    "terms_df.to_csv(\"./output/dhterms/ctgov_digitalhealthterms.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41259ff7",
   "metadata": {},
   "source": [
    "## Pubmed: June 29, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ced87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DHTermSearch import get_pmc_ids, fetch_full_pmc_text\n",
    "\n",
    "# Get all pmc_ids with \"digital health\" in Title or Abstract that occur between 2012/01/01 and 2022/12/31\n",
    "search_params = {\"db\":\"pmc\",\n",
    "                 \"retmode\":\"json\",\n",
    "                 \"mindate\":\"2012/01/01\",\n",
    "                 \"maxdate\":\"2022/12/31\",\n",
    "                }\n",
    "all_pmc_ids = []\n",
    "for field in [\"Body - Key Terms\", \"Abstract\", \"Title\"]: #, \n",
    "    search_params[\"field\"] = field\n",
    "    pmc_ids = get_pmc_ids(query='\"digital health\"', search_params=search_params)\n",
    "    pmc_ids = pmc_ids[\"esearchresult\"][\"idlist\"]\n",
    "    all_pmc_ids.extend(pmc_ids)\n",
    "    print(\"Articles with 'digital health' in %s:\"%field, len(pmc_ids))\n",
    "\n",
    "print(\"Total values:\", len(all_pmc_ids))\n",
    "all_pmc_ids = list(set(all_pmc_ids))\n",
    "print(\"Total values - deduplicated:\", len(all_pmc_ids))\n",
    "\n",
    "# Get all full text and abstracts from each Digital health PMC paper\n",
    "all_pmc_texts = pd.DataFrame()\n",
    "for i in range(0,len(all_pmc_ids), 200):\n",
    "    print(i,min(len(all_pmc_ids), i+200))\n",
    "    \n",
    "    pmc_texts = fetch_full_pmc_text(all_pmc_ids[i:min(len(all_pmc_ids), i+200)])\n",
    "    \n",
    "    pmc_df = pd.DataFrame(pmc_texts)\n",
    "    all_pmc_texts = pd.concat([all_pmc_texts, pmc_df])\n",
    "\n",
    "# Clean up values\n",
    "all_pmc_texts = all_pmc_texts.drop_duplicates([\"pmc_id\"])\n",
    "all_pmc_texts = all_pmc_texts.set_index(\"pmc_id\")\n",
    "all_pmc_texts.to_parquet(\"./output/dhterms/pmc_digitalhealthtexts.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmc_texts_df = pd.read_parquet(\"./output/dhterms/pmc_digitalhealthtexts.parquet\")\n",
    "\n",
    "# Remove stopwords, numnbers, extra spaces, and special characters \n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords = all_stopwords + [\"patient\", \"subject\", \"participant\", \"studies\", \"study\", \"years\", \"months\",\n",
    "                  \"individual\", \"weeks\", \"eg\",  \"diagnosis\", \"participation\", \"participate\", \"patients\", \"participants\"]\n",
    "\n",
    "pmc_texts_df[\"text_clean\"] = pmc_texts_df[\"text\"].apply(lambda text: re.sub('[\\n\\t\\-,]', ' ', text))\n",
    "pmc_texts_df[\"text_clean\"] = pmc_texts_df[\"text_clean\"].apply(lambda text: re.sub('[^A-Za-z ]+', ' ', text))\n",
    "pmc_texts_df[\"text_clean\"] = pmc_texts_df[\"text_clean\"].apply(lambda text: re.sub('[ ]+', ' ', text))\n",
    "pmc_texts_df[\"text_clean\"] = pmc_texts_df[\"text_clean\"].str.lower()\n",
    "\n",
    "text = \" \".join(list(pmc_texts_df[\"text_clean\"]))\n",
    "text = text.split(\" \")\n",
    "text = [t for t in text if t not in all_stopwords if len(t)>3]\n",
    "\n",
    "# 1,2, and 3-grams that occur at least 200 times in article text\n",
    "terms_df = pd.DataFrame()\n",
    "\n",
    "for gram in range(1,4):\n",
    "    ngram_counts = Counter(ngrams(text, gram))\n",
    "    ngram_list = [(\" \".join(i), ngram_counts[i]) for i in ngram_counts if ngram_counts[i]]\n",
    "    ngram_df = pd.DataFrame(ngram_list, columns = [\"term\", \"count\"])\n",
    "    ngram_df = ngram_df.sort_values(\"count\", ascending=False)\n",
    "    \n",
    "    mean = ngram_df[\"count\"].mean()\n",
    "    std = ngram_df[\"count\"].std()\n",
    "    \n",
    "    print(len(ngram_df)) # 267323, 7244453, 18324292\n",
    "    ngram_df = ngram_df[ngram_df[\"count\"]>499]\n",
    "    terms_df = pd.concat([terms_df, ngram_df])\n",
    "    \n",
    "print(len(terms_df)) # 6677\n",
    "terms_df.to_csv(\"./output/dhterms/pubmed_digitalhealthterms.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7bc7a0",
   "metadata": {},
   "source": [
    "# Get digital health notes: July 3, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b9cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask_jobqueue import SGECluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "i=0\n",
    "# Load cluster\n",
    "while True:\n",
    "    try:\n",
    "        cluster =  SGECluster(\n",
    "            queue = 'DEID',\n",
    "            cores = 4,\n",
    "            memory = '48GiB',\n",
    "            walltime = '04:00:00',\n",
    "            death_timeout = 60,\n",
    "            local_directory = f'{os.getcwd()}/dask_temp',\n",
    "            log_directory = f'{os.getcwd()}/dask_temp/dask_log',\n",
    "            python = sys.executable,\n",
    "            #python = \"/wynton/group/jhadmin/base-clone/bin/python\",\n",
    "            resource_spec='DEID',\n",
    "            scheduler_options = {\n",
    "                'host': f'DEID{40000 + i}'\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        print(f'Using Port {40000 + i}...')\n",
    "        break\n",
    "    i += 1\n",
    "    if i%1000==0: print(i)\n",
    "\n",
    "cluster.scale(250)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)\n",
    "\n",
    "def load_register_table(data_asset, table, **kwargs):\n",
    "    return dd.read_parquet(f'/DEID/{data_asset}/{table}/', **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load search terms and get notes\n",
    "# Some table and column names here are changed to generic values due to University policy on data use\n",
    "note_data = load_register_table(\"DEID_CDW\", \"note_table\")\n",
    "\n",
    "search_list = pd.read_csv(\"./searchterms.csv\", encoding='mac-roman')\n",
    "search_list = search_list[search_list[\"EMERSE_check\"] == \"Yes\"]\n",
    "search_list = search_list[search_list[\"Group\"]!=\"Telehealth\"] # Telehealth removed\n",
    "\n",
    "# For each type of search term, select note IDs and create a \"partition\"\n",
    "for group in list(search_list[\"Group\"].unique()):\n",
    "    \n",
    "    search_terms = search_list[search_list[\"Group\"]==group]\n",
    "    search_terms = \"|\".join(search_terms[\"Term\"].to_list())\n",
    "\n",
    "    # Remove irrelevant note types\n",
    "    note_data = note_data[~note_data[\"encounter_type\"].str.contains(\"Letter|Prepare |Documentation|STOR|Prep \", na=False)]\n",
    "    note_data = note_data[note_data[\"note_text\"].str.lower().str.contains(search_terms)]\n",
    "    digital_df = digital_rdd.compute()\n",
    "    digital_df.to_parquet(f\"./output/dhnotes/raw/{group}_notes.parquet.gzip\", compression=\"gzip\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0192e",
   "metadata": {},
   "source": [
    "## Add encounter information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3affd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "### Load values and clean up + add encounter/patient metadata information\n",
    "# Load as Dask DataFrame\n",
    "note_files = glob.glob(\"./output/dhnotes/raw/*\")\n",
    "\n",
    "notes_df = pd.DataFrame()\n",
    "for file in note_files:\n",
    "    curr_df = pd.read_parquet(file)\n",
    "    notes_df = pd.concat([curr_df, notes_df])\n",
    "\n",
    "notes_df = dd.from_pandas(notes_df, npartitions=200)\n",
    "\n",
    "# Add encounter information\n",
    "encounter_rdd = load_register_table(\"DEID_CDW\", \"encounter_table\")\n",
    "merged_df = notes_df.merge(encounter_rdd, right_on='encounter_id', left_on=\"encounter_id\", how=\"inner\")\n",
    "merged_df = merged_df.compute()\n",
    "\n",
    "# Add year information and lower case text column\n",
    "merged_df[\"year\"] = [None if n is None else n.year for n in merged_df['date']]\n",
    "merged_df[\"note_text_clean\"] = [t.lower() for t in merged_df[\"note_text\"]]\n",
    "\n",
    "print(f\"Initial note count: {merged_df.shape}\")\n",
    "print(f\"Initial patient count: {merged_df['patientid'].nunique()}\")\n",
    "\n",
    "# drop duplicates (remove all templated instructions)\n",
    "# This does not keep any duplicates\n",
    "clean_df = merged_df.drop_duplicates(subset=[\"note_text_clean\"],keep=False)\n",
    "print(f\"Dedup note count: {clean_df.shape}\")\n",
    "print(f\"Dedup patient count: {clean_df['patientid'].nunique()}\")\n",
    "\n",
    "# Remove notes after 2022 or before 2012\n",
    "clean_df = clean_df[(clean_df[\"year\"]<2023)]\n",
    "clean_df = clean_df[(clean_df[\"year\"]>2011)]\n",
    "print(f\"Time window note count: {clean_df.shape}\")\n",
    "print(f\"Time window patient count: {clean_df['patientid'].nunique()}\")\n",
    "\n",
    "# drop zoom links and patient portal information\n",
    "# these values were manually curated from \n",
    "remove_zoom = [\"zoom.us\", \"mychart app\", \"on your smartphone with the app\",\n",
    "              \"download the free mychart\",\"download the mychart\",\"on-line and via mobile app\",\n",
    "               \"please follow the link from your smartphone\" ]\n",
    "clean_df = clean_df[~clean_df[\"note_text_clean\"].str.contains(\"|\".join(remove_zoom))]\n",
    "\n",
    "print(f\"Without zoom link / patient portal notes count: {clean_df.shape}\")\n",
    "print(f\"Without zoom link / patient portal patient count: {clean_df['patientid'].nunique()}\")\n",
    "\n",
    "# Add term information\n",
    "search_list = pd.read_csv(\"./searchterms.csv\", encoding='mac-roman')\n",
    "search_list = search_list[search_list[\"EMERSE_check\"] == \"Yes\"]\n",
    "search_list = search_list[search_list[\"Group\"]!=\"Telehealth\"] # Telehealth removed\n",
    "\n",
    "for term, term_clean in zip(search_list[\"Term\"], search_list[\"Term_clean\"]):\n",
    "    clean_df[term_clean] = clean_df[\"note_text_clean\"].str.contains(term)\n",
    "\n",
    "# Save final values\n",
    "clean_df.to_parquet(\"./output/dhnotes/DH_annotated_notes.parquet.gzip\", compression=\"gzip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb7e7a",
   "metadata": {},
   "source": [
    "## Save demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0685cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in values\n",
    "notes_df = pd.read_parquet(\"./output/dhnotes/DH_annotated_notes.parquet.gzip\")\n",
    "\n",
    "# Get patient metadata using values from previous set\n",
    "patient_rdd = load_register_table(\"DEID_CDW\", \"patient_table\")\n",
    "patient_rdd = patient_rdd[patient_rdd[\"iscurrent\"]==1]\n",
    "patient_df = patient_rdd[patient_rdd[\"patientid\"].isin(list(notes_df[\"patientid\"].unique()))]\n",
    "patient_df = patient_df.compute()\n",
    "print(patient_df.shape)\n",
    "\n",
    "patient_df.to_parquet(\"./output/dhnotes/demographics.parquet.gzip\", compression=\"gzip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.figures import mask_small_group\n",
    "\n",
    "# Get overall demographics to compare\n",
    "patient_df = pd.read_parquet(\"./output/dhnotes/demographics.parquet.gzip\")\n",
    "\n",
    "# filter to get patients with notes who have notes after 2012 or before 2023\n",
    "notes_meta_rdd = load_register_table(\"DEID_CDW\", \"note_table\")\n",
    "print(\"Total patients with notes:\", notes_meta_rdd[\"patientid\"].nunique().compute())\n",
    "\n",
    "notes_meta_rdd = notes_meta_rdd[(notes_meta_rdd[\"deid_service_date\"]>\"2012\")]\n",
    "notes_meta_rdd = notes_meta_rdd[(notes_meta_rdd[\"deid_service_date\"]<\"2023\")]\n",
    "\n",
    "# Get total notes per year for these patients\n",
    "notes_meta_rdd['year'] = notes_meta_rdd[\"deid_service_date\"].dt.year\n",
    "print(notes_meta_rdd[\"year\"].value_counts().compute())\n",
    "\n",
    "# add patient birthdays to note metadata\n",
    "notes_meta_rdd = notes_meta_rdd[[\"patientid\", \"deid_service_date\"]] \n",
    "notes_demo_rdd = patient_rdd.merge(notes_meta_rdd,how='inner',on='patientid')\n",
    "\n",
    "# add age info\n",
    "notes_demo_rdd[\"birthdate\"] = notes_demo_rdd[\"birthdate\"].astype('datetime64[ns]')\n",
    "notes_demo_rdd[\"age_at_note\"] = (notes_demo_rdd[\"deid_service_date\"] - notes_demo_rdd[\"birthdate\"]).dt.days / 365\n",
    "\n",
    "# remove patients with digital health notes\n",
    "# Total unique patient epic ids with notes without DH terms: 2797871\n",
    "demographics_df = pd.read_parquet(\"./output/dhnotes/demographics.parquet.gzip\")\n",
    "notes_demo_rdd = notes_demo_rdd[~notes_demo_rdd[\"patientid\"].isin(list(demographics_df[\"patientid\"].unique()))]\n",
    "\n",
    "# Get overall age of notes\n",
    "print(notes_demo_rdd[\"age_at_note\"].describe().compute().loc[[\"mean\", \"std\", \"50%\", \"25%\", \"75%\"]])\n",
    "\n",
    "# get unique patient data for categorical demographic calculations\n",
    "notes_demo_rdd = notes_demo_rdd.drop_duplicates('patientid')\n",
    "notes_demo_df = notes_demo_rdd.persist()\n",
    "print(\"Total patients between 2012-2022 without DH notes:\", notes_demo_df[\"patientid\"].nunique().compute())\n",
    "\n",
    "'''\n",
    "Total patients between 2012-2022 without DH notes: 2170780\n",
    "'''\n",
    "\n",
    "# get categorical demographcs\n",
    "demo_col = ['sex', 'preferredlanguage', 'mychartstatus', 'ucsfderivedraceethnicity_x']\n",
    "all_demo_df = pd.DataFrame()\n",
    "\n",
    "for demo in demo_col:\n",
    "    demo_series = notes_demo_df[demo].value_counts().compute()\n",
    "    \n",
    "    # get values\n",
    "    demo_df = demo_series.reset_index()\n",
    "    demo_df.columns = [\"value\", \"count\"]\n",
    "    demo_df[\"category\"] = demo\n",
    "    \n",
    "    # mask values with less than 10 counts and get masked proportions\n",
    "    demo_df = mask_small_group(demo_df, min_n=10)\n",
    "    all_demo_df = pd.concat([all_demo_df, demo_df])\n",
    "    \n",
    "all_demo_df.to_csv(\"./output/no_dhnotes_demographics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0199bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in values\n",
    "notes_df = pd.read_parquet(\"./output/dhnotes/DH_annotated_notes.parquet.gzip\")\n",
    "demographics_df = pd.read_parquet(\"./output/dhnotes/demographics.parquet.gzip\")\n",
    "\n",
    "# get age of notes\n",
    "notes_demo_df = notes_df.merge(demographics_df, how=\"left\", on=\"patientid\")\n",
    "notes_demo_df[\"birthdate\"] = notes_demo_df[\"birthdate\"].astype('datetime64[ns]')\n",
    "notes_demo_df[\"date\"] = notes_demo_df[\"date\"].astype('datetime64[ns]')\n",
    "\n",
    "notes_demo_df[\"age_at_note\"] = (notes_demo_df[\"date\"] - notes_demo_df[\"birthdate\"]).dt.days / 365\n",
    "print(notes_demo_rdd[\"age_at_note\"].describe().compute().loc[[\"mean\", \"std\", \"50%\", \"25%\", \"75%\"]])\n",
    "\n",
    "'''\n",
    "mean    37.348978\n",
    "std     24.883279\n",
    "50%     36.032877\n",
    "25%     15.054795\n",
    "75%     58.268493\n",
    "'''\n",
    "\n",
    "# Get values for DH note patients\n",
    "all_demo_df = pd.DataFrame()\n",
    "\n",
    "for demo in demo_col:\n",
    "    demo_series = demographics_df[demo].value_counts()\n",
    "    \n",
    "    # get values\n",
    "    demo_df = demo_series.reset_index()\n",
    "    demo_df.columns = [\"value\", \"count\"]\n",
    "    demo_df[\"category\"] = demo\n",
    "    \n",
    "    # mask values with less than 10 counts and get masked proportions\n",
    "    demo_df = mask_small_group(demo_df, min_n=10)\n",
    "    all_demo_df = pd.concat([all_demo_df, demo_df])\n",
    "    \n",
    "all_demo_df.to_csv('./output/dhnotes_demographics.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking when the \"unknown\" values occur for patients without DH notes\n",
    "# And in which departments\n",
    "from utils.figures import mask_small_group\n",
    "\n",
    "# Get overall demographics to compare\n",
    "patient_rdd = load_register_table(\"DEID_CDW\", \"patient_table\")\n",
    "patient_rdd = patient_rdd[patient_rdd[\"iscurrent\"]==1]\n",
    "\n",
    "# filter to get patients with notes who have notes after 2012 or before 2023\n",
    "notes_meta_rdd = load_register_table(\"DEID_CDW\", \"note_table\")\n",
    "\n",
    "notes_meta_rdd = notes_meta_rdd[(notes_meta_rdd[\"note_date\"]>\"2012\")]\n",
    "notes_meta_rdd = notes_meta_rdd[(notes_meta_rdd[\"note_date\"]<\"2023\")]\n",
    "\n",
    "# add patient birthdays to note metadata\n",
    "#notes_meta_rdd = notes_meta_rdd[[\"patientid\", \"note_date\"]] \n",
    "notes_demo_rdd = patient_rdd.merge(notes_meta_rdd,how='inner',on='patientid')\n",
    "\n",
    "# Get total notes per year for these patients\n",
    "notes_demo_rdd['year'] = notes_demo_rdd[\"note_date\"].dt.year\n",
    "\n",
    "# add age info\n",
    "notes_demo_rdd[\"birthdate\"] = notes_demo_rdd[\"birthdate\"].astype('datetime64[ns]')\n",
    "notes_demo_rdd[\"age_at_note\"] = (notes_demo_rdd[\"note_date\"] - notes_demo_rdd[\"birthdate\"]).dt.days / 365\n",
    "\n",
    "# remove patients with digital health notes\n",
    "# Total unique patient epic ids with notes without DH terms: 2797871\n",
    "demographics_df = pd.read_parquet(\"./output/dhnotes/demographics.parquet.gzip\")\n",
    "\n",
    "# Only limit to patients who have \"unknown\" mychart status\n",
    "notes_demo_rdd = notes_demo_rdd[~notes_demo_rdd[\"patientid\"].isin(list(demographics_df[\"patientid\"].unique()))]\n",
    "notes_demo_rdd = notes_demo_rdd.dropna(subset=\"mychartstatus\")\n",
    "notes_demo_rdd = notes_demo_rdd[notes_demo_rdd[\"mychartstatus\"].str.contains(\"unspecified\", case=False, na=False)]\n",
    "\n",
    "# Characterize notes per year for patients with \"unspecified\" mychart status (run 10/4)\n",
    "notes_demo_rdd = notes_demo_rdd.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef48a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0447ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f691e13c",
   "metadata": {},
   "source": [
    "## Get digital health sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from utils.figures import retrieve_dh_sentences\n",
    "\n",
    "### Load notes and terms\n",
    "notes_df = pd.read_parquet(\"./output/dhnotes/DH_annotated_notes.parquet.gzip\")\n",
    "\n",
    "terms = pd.read_csv(\"./searchterms.csv\", header=0, encoding='mac-roman')\n",
    "terms = terms[terms[\"EMERSE_check\"] == \"Yes\"]\n",
    "terms = terms[terms[\"File_group\"]!=\"Telehealth\"] # Telehealth removed\n",
    "\n",
    "# clean up\n",
    "notes_df[\"note_text_sent\"] = notes_df[\"note_text_clean\"].apply(lambda t: t.replace(\"*****\", \"\"))\n",
    "notes_df[\"note_text_sent\"] = notes_df[\"note_text_sent\"].apply(lambda t: sent_tokenize(t))\n",
    "\n",
    "# extract sentences that mention digital health\n",
    "dh_terms = list(terms[\"Term\"])\n",
    "dh_terms_clean = list(terms[\"Term_clean\"])\n",
    "\n",
    "for term, term_clean in zip(dh_terms, dh_terms_clean):\n",
    "    print(term_clean)\n",
    "    curr_df = notes_df[notes_df[term_clean]]\n",
    "    curr_df[\"note_text_dh_sent_extended\"] = retrieve_dh_sentences(list(curr_df[\"note_text_sent\"]), term, extend=True)\n",
    "    curr_df[\"note_text_dh_sent\"] = retrieve_dh_sentences(list(curr_df[\"note_text_sent\"]), term, extend=False)\n",
    "    \n",
    "    curr_df = curr_df[[\"note_id\", \"encounterkey\", \"note_text\", \"note_text_dh_sent\", term_clean, \n",
    "                       \"provider_specialty\", \"diagnosis\", \"encounter_department_specialty\", \"note_text_dh_sent_extended\"]]\n",
    "    if len(curr_df)>0:\n",
    "        curr_df.to_parquet(f\"./output/dhnotes/sentences/{term_clean}.parquet.gzip\", compression=\"gzip\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a56a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c3e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e4ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef62ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c85b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ba20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
