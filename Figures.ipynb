{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\") #paper, notebook, talk, poster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load master values for figures\n",
    "notes_df = pd.read_parquet(\"./output/dhnotes/DH_annotated_notes.parquet.gzip\")\n",
    "terms = pd.read_csv(\"./searchterms.csv\", header=0, encoding='mac-roman')\n",
    "terms = terms[terms[\"EMERSE_check\"] == \"Yes\"]\n",
    "terms = terms[terms[\"File_group\"]!=\"Telehealth\"] # Telehealth removed\n",
    "\n",
    "# term columns\n",
    "term_cols = list(terms[\"Term_clean\"])\n",
    "term_cols = [t for t in term_cols if t in notes_df.columns]\n",
    "\n",
    "# Add categories \n",
    "category_dict = dict(terms.groupby(\"Category\")[\"Term_clean\"].apply(\"|\".join))\n",
    "\n",
    "for category in category_dict:\n",
    "    notes_df[category] = notes_df[category_dict[category].split(\"|\")].sum(axis=1)\n",
    "    notes_df[category] = notes_df[category] > 0 # becomes true/false\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1: Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demographics\n",
    "dh_demo = pd.read_csv(\"./output/dhnotes_demographics.csv\", index_col=0)\n",
    "no_dh_demo = pd.read_csv(\"./output/no_dhnotes_demographics.csv\", index_col=0)\n",
    "\n",
    "# Other params\n",
    "stats_demo_df = pd.DataFrame()\n",
    "demo_dict = {'sex':\"Sex\", 'preferredlanguage':\"Preferred Language\", \n",
    "             'ucsfderivedraceethnicity_x':\"Race/Ethnicity\", 'mychartstatus': \"MyChart Status\"}\n",
    "\n",
    "# Get stats for each group\n",
    "for group in ['sex', 'ucsfderivedraceethnicity_x', 'preferredlanguage', 'mychartstatus']:\n",
    "    dh_subset = dh_demo[dh_demo[\"category\"]==group][[\"value\", \"count\", \"proportion\"]]\n",
    "    no_dh_subset = no_dh_demo[no_dh_demo[\"category\"]==group][[\"value\", \"count\", \"proportion\"]]\n",
    "    \n",
    "    # Merge and add statistics\n",
    "    demo_df = no_dh_subset.merge(dh_subset, how=\"inner\", on=\"value\", suffixes = ('', '_dh'),).set_index(\"value\")\n",
    "    demo_df = demo_df.replace(\"<10\", np.nan)\n",
    "    demo_df = demo_df.astype(float, errors=\"ignore\")\n",
    "    demo_df.loc[demo_dict[group]+\" (Total)\"] = demo_df.sum(axis=0, numeric_only=True)\n",
    "    demo_df = demo_df.sort_values(\"count_dh\", ascending=False) # sort by counts in DH note group\n",
    "    \n",
    "    demo_df[\"Digital health note\"] = [np.nan if np.isnan(c)\n",
    "                                      else str(int((c)))+\" (%s%%)\"%(\"{:.1f}\".format(100*float(p))) if c!=\"<10\" \n",
    "                                    else c for p,c in zip(demo_df[\"proportion_dh\"], demo_df[\"count_dh\"])]\n",
    "    \n",
    "    demo_df[\"No digital health note\"] = [np.nan if np.isnan(c)\n",
    "                                      else str(int((c)))+\" (%s%%)\"%(\"{:.1f}\".format(100*float(p))) if c!=\"<10\" \n",
    "                                              else c for p,c in zip(demo_df[\"proportion\"], demo_df[\"count\"])]\n",
    "\n",
    "    # Add statistics\n",
    "    chi_df = demo_df[[\"count\", \"count_dh\"]]\n",
    "    chi_df = chi_df.replace(\"<10\", np.nan)\n",
    "    chi_df = chi_df.astype(float)\n",
    "    chi_df = chi_df.dropna(how=\"any\")\n",
    "   \n",
    "    # Perform the chi-square test\n",
    "    chi2, p_value, dof, expected = chi2_contingency(chi_df.values)\n",
    "\n",
    "     # Create final demographics table 1 \n",
    "    demo_df = demo_df[[\"No digital health note\", \"Digital health note\"]]\n",
    "    demo_df[\"pvalue\"] = [\"\"]+[p_value]+[\"\"]*(len(demo_df)-2)\n",
    "    demo_df = demo_df.replace(np.nan, \"<10\")\n",
    "    stats_demo_df = pd.concat([stats_demo_df, demo_df])\n",
    "\n",
    "stats_demo_df.to_csv(\"./output/figures/Table1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_demo = pd.read_csv(\"./output/dhnotes_demographics.csv\", index_col=0)\n",
    "no_dh_demo = pd.read_csv(\"./output/no_dhnotes_demographics.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Note distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure S2A: Heatmap of terms across departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "x_value = \"encounterdepartmentspecialty\"\n",
    "\n",
    "values_df = notes_df.copy(deep=True)\n",
    "values_df = values_df[[\"note_id\", \"patientid\", x_value, \"providertype\"]+term_cols]\n",
    "values_df[\"count\"] = 1\n",
    "\n",
    "### Supplemental table 1. Distribution of note terms across departments\n",
    "numbers_df = values_df.groupby([x_value])[\"count\"].sum().reset_index()\n",
    "numbers_df = numbers_df.sort_values(\"count\", ascending=False)\n",
    "numbers_df.to_csv(\"./output/figures/supplement/TableS1Data.csv\")\n",
    "\n",
    "# print\n",
    "top_departments = numbers_df[:25][\"encounter_department_specialty\"]\n",
    "print(\"Number of DH notes per department (top 25)\")\n",
    "print(numbers_df[:25])\n",
    "print()\n",
    "\n",
    "### Supplemental table 2. Distribution of note terms across different departments\n",
    "values_df = notes_df.copy(deep=True)\n",
    "values_df = values_df[['patientid', 'encounterkey', x_value]+term_cols]\n",
    "\n",
    "# pivot to table containing columns [\"term\", \"termpresent\"] indexed by [encounterkey, patientid, and x_value]\n",
    "values_df = values_df.melt(id_vars=['encounterkey', 'patientid', x_value], \n",
    "                           value_vars=term_cols, var_name='term', value_name='termPresent')\n",
    "values_df = values_df[values_df[\"termPresent\"]]\n",
    "\n",
    "# count number of DH terms present\n",
    "values_df = values_df.groupby([\"term\", x_value]).sum(numeric_only=False)[[\"termPresent\"]].reset_index()\n",
    "\n",
    "# save counts by [term, department]\n",
    "values_df = values_df.sort_values(\"termPresent\", ascending=False)\n",
    "values_df.to_csv(\"./output/figures/supplement/TableS2Data.csv\")\n",
    "\n",
    "# print top terms (across all notes)\n",
    "top_terms = values_df.groupby(\"term\")[[\"termPresent\"]].sum().sort_values(\"termPresent\", ascending=False)\n",
    "print('Number of top 10 digital health term notes (may be greater than # notes due to notes with multiple DH terms)')\n",
    "print(top_terms)\n",
    "\n",
    "top_terms = top_terms[:10].index\n",
    "\n",
    "# Get depts and terms that have at least 1000 values\n",
    "heatmap_terms = values_df.groupby(\"term\")[[\"termPresent\"]].sum().sort_values(\"termPresent\", ascending=False)\n",
    "heatmap_terms = heatmap_terms[heatmap_terms[\"termPresent\"] > 999]\n",
    "values_df = values_df[values_df[\"term\"].isin(list(heatmap_terms.index))]\n",
    "\n",
    "heatmap_depts = values_df.groupby(\"encounter_department_specialty\")[[\"termPresent\"]].sum().sort_values(\"termPresent\", ascending=False)\n",
    "heatmap_depts = heatmap_depts[heatmap_depts[\"termPresent\"] > 999]\n",
    "values_df = values_df[values_df[\"encounter_department_specialty\"].isin(list(heatmap_depts.index))]\n",
    "\n",
    "# Plot values\n",
    "heatmap_df = values_df.pivot(columns=\"term\", index =\"encounter_department_specialty\", values=\"termPresent\")\n",
    "heatmap_df = heatmap_df.replace(np.nan,0)\n",
    "ax = sns.clustermap(heatmap_df, vmax=800, vmin=-150, **{\"cmap\":\"BuPu\"})\n",
    "ax.figure.savefig(\"./output/figures/supplement/Figure2SA.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure S2: Distribution of top terms across departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Figure 2. Bar plot of top terms and departments\n",
    "# get only top 5 departments\n",
    "x_n = 5\n",
    "\n",
    "top_p = list(top_departments)[:x_n]\n",
    "plot_df = values_df.copy(deep=True)\n",
    "plot_df[x_value] = [\"Unspecified\" if p==\"UCSF\" \n",
    "                    else p if p in top_p\n",
    "                    else \"Other\" for p in plot_df[x_value]]\n",
    "plot_df = plot_df[plot_df[x_value].isin(list(top_p))]\n",
    "\n",
    "# get only top 10 term values\n",
    "plot_df = plot_df[plot_df[\"term\"].isin(top_terms[:10])]\n",
    "xtab_df = pd.crosstab(index=plot_df[x_value], columns=plot_df.term, \n",
    "                      values=plot_df.termPresent, aggfunc=np.sum, normalize=False)\n",
    "notes_order = xtab_df.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "# crosstab for barplot\n",
    "xtab_df_norm = pd.crosstab(index=plot_df[x_value], columns=plot_df.term, \n",
    "                      values=plot_df.termPresent, aggfunc=np.sum, normalize='index')\n",
    "xtab_df_norm = xtab_df_norm.loc[top_p]\n",
    "ax = xtab_df_norm.plot(kind=\"bar\", stacked=True, rot=0, figsize=(10, 8))\n",
    "ax.legend(title='Digital health term', bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.set(xlabel=None)\n",
    "ax.figure.savefig(\"./output/figures/Figure2A.pdf\", bbox_inches='tight')\n",
    "\n",
    "# Get raw data\n",
    "xtab_df = xtab_df.replace(np.nan, 0)\n",
    "print(xtab_df.shape)\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(xtab_df.loc[top_p].values)\n",
    "\n",
    "# Save raw data\n",
    "xtab_df = xtab_df.round(3)\n",
    "xtab_df_norm = xtab_df_norm.round(3)\n",
    "xtab_df.to_csv(\"./output/figures/raw/Figure2AData_1.csv\")\n",
    "xtab_df_norm.to_csv(\"./output/figures/raw/Figure2AData_2.csv\")\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2SB: Top terms across provider type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value = \"providertype\"#\"prov_specialty\" #\"primarycoveragefinancialclass\"\n",
    "\n",
    "values_df = notes_df.copy(deep=True)\n",
    "values_df = values_df[[x_value, \"encounterkey\"]+term_cols]\n",
    "values_df[\"count\"] = 1\n",
    "\n",
    "# Get counts by provider and term\n",
    "plot_df = values_df.groupby(x_value).sum()\n",
    "plot_df.to_csv(\"./output/figures/raw/Figure2SBData.csv\") # save all values\n",
    "plot_df = plot_df.sort_values(\"count\").iloc[-25:]\n",
    "del plot_df[\"count\"]\n",
    "top_terms = plot_df.sum(axis=0).sort_values().iloc[-25:].index\n",
    "plot_df = plot_df[top_terms]\n",
    "\n",
    "ax = sns.clustermap(plot_df, vmax=800, vmin=-150, **{\"cmap\":\"BuPu\"})\n",
    "ax.figure.savefig(\"./output/figures/supplement/Figure2SB.pdf\", bbox_inches='tight')\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(plot_df.values)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Degrees of freedom:\", dof)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3: Note occurence over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3A: Digital health term occurence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.figures import plot_notes_over_time, calculate_cagr, ridge_plot\n",
    "\n",
    "# Get all note counts\n",
    "all_note_counts_df = pd.DataFrame.from_dict({2021:14205387,\n",
    "                                   2020:13487925,\n",
    "                                   2019:12773799,\n",
    "                                   2022:11521289,\n",
    "                                   2018:11416946,\n",
    "                                   2017:10749857,\n",
    "                                   2016:10453727,\n",
    "                                   2013:10434202,\n",
    "                                   2015: 9714333,\n",
    "                                   2014: 8671952,\n",
    "                                   2012: 5685316}, orient=\"index\")\n",
    "\n",
    "all_note_counts_df = all_note_counts_df.reset_index()\n",
    "all_note_counts_df[\"Digital health term\"] = \"All notes\"\n",
    "all_note_counts_df.columns = [\"Year\", \"Count\",\"Digital health term\", ]\n",
    "total_cagr=calculate_cagr(all_note_counts_df, group_col=\"Digital health term\", time_col=\"Year\", count_col=\"Count\")\n",
    "print(total_cagr)\n",
    "'''\n",
    " CAGR (%)      Count\n",
    "Digital health term                     \n",
    "All notes            7.318513  119114733\n",
    "'''\n",
    "\n",
    "### Figure 3A. Change in term type over time\n",
    "values_df = notes_df[[\"note_id\", \"year\", \"note_text_clean\"] + term_cols]\n",
    "values_df = values_df.set_index(\"note_id\")\n",
    "values_df = values_df.groupby(\"year\").sum()\n",
    "values_df = values_df.stack().reset_index()\n",
    "values_df.columns = [\"Year\", \"Digital health term\", \"Count\"]\n",
    "\n",
    "# Get CAGR values\n",
    "cagr_df = calculate_cagr(values_df, group_col=\"Digital health term\", time_col=\"Year\", count_col=\"Count\")\n",
    "\n",
    "# add values for all digital health notes\n",
    "dh_note_counts_df = values_df.groupby(\"Year\").sum()[[\"Count\"]]\n",
    "dh_note_counts_df = dh_note_counts_df.reset_index()\n",
    "dh_note_counts_df[\"Digital health term\"] = \"DH notes\"\n",
    "dh_note_counts_df.columns = [\"Year\", \"Count\",\"Digital health term\", ]\n",
    "dh_cagr = calculate_cagr(dh_note_counts_df, group_col=\"Digital health term\", time_col=\"Year\", count_col=\"Count\")\n",
    "print(dh_cagr)\n",
    "'''\n",
    "CAGR (%)   Count\n",
    "Digital health term                   \n",
    "DH notes             26.883556  226898\n",
    "'''\n",
    "# add values for all & DH notes notes\n",
    "cagr_df = pd.concat([cagr_df,dh_cagr, total_cagr])\n",
    "cagr_df.to_csv(\"./output/figures/raw/Figure3AData.csv\")\n",
    "\n",
    "# Get largest departments\n",
    "top_n = 10\n",
    "top_values = cagr_df.sort_values(\"Count\").iloc[-(top_n+2):].index #cagr_df[cagr_df[\"Count\"]>999].iloc[list(range(-top_n, 0))].index\n",
    "#top_values = list(values_df.groupby(\"Digital health term\")[\"Count\"].sum(numeric_only=True).sort_values()[-top_n:].index)\n",
    "plot_df = values_df[values_df[\"Digital health term\"].isin(top_values)]\n",
    "plot_df = pd.concat([plot_df, dh_note_counts_df, all_note_counts_df])\n",
    "plot_df = plot_df.reset_index(drop=True)\n",
    "\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "facet_order = list(top_values)\n",
    "facet_order.reverse()\n",
    "order = [\"All notes\", \"DH notes\"] + [f for f in facet_order if f not in (\"All notes\", \"DH notes\")]\n",
    "\n",
    "# colors\n",
    "pal = sns.cubehelix_palette(start=0.5, rot=-0.45, dark=0.1, light=.6, gamma=0.95, reverse=False, hue=0.9,as_cmap=True)\n",
    "\n",
    "# Add color by CAGR\n",
    "hue=\"Digital health term\"\n",
    "\n",
    "plot_df = plot_df[plot_df[hue].isin(order)]\n",
    "plot_df[\"CAGR\"] = plot_df[hue].map(cagr_df[\"CAGR (%)\"])\n",
    "vmax = plot_df['CAGR'].max()\n",
    "vmin = plot_df['CAGR'].min()\n",
    "g = ridge_plot(plot_df, hue=hue, order=order, pal=pal, vmax = vmax,vmin=vmin)\n",
    "g.figure.savefig(\"./output/figures/Figure3A.pdf\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Figure 3B data. \n",
    "plot_df = notes_df.groupby([\"year\", \"encounter_department_specialty\"])[\"note_id\"].count().reset_index()\n",
    "plot_df = plot_df.sort_values(\"note_id\", ascending=False)\n",
    "plot_df.columns = [\"Year\", \"Specialty\", \"Count\"]\n",
    "dh_note_counts_df.columns = [\"Year\",  \"Count\", \"Specialty\",]\n",
    "all_note_counts_df.columns = [\"Year\",  \"Count\", \"Specialty\",]\n",
    "plot_df = pd.concat([plot_df, dh_note_counts_df, all_note_counts_df])\n",
    "plot_df = plot_df.reset_index(drop=True)\n",
    "\n",
    "# Save all cagr values\n",
    "cagr_df = pd.concat([cagr_df,dh_cagr, total_cagr])\n",
    "cagr_df = calculate_cagr(plot_df, group_col=\"Specialty\", time_col=\"Year\", count_col=\"Count\")\n",
    "cagr_df.to_csv(\"./output/figures/raw/Figure3BData.csv\")\n",
    "\n",
    "top_values = cagr_df.sort_values(\"Count\").iloc[-(top_n+2):].index #[cagr_df[\"Count\"]>999].iloc[list(range(-top_n, 0))+list(range(0, top_n))].index\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "facet_order = list(top_values)\n",
    "facet_order.reverse()\n",
    "order = [\"All notes\", \"DH notes\"] + [f for f in facet_order if f not in (\"All notes\", \"DH notes\")]\n",
    "\n",
    "# colors\n",
    "pal = sns.cubehelix_palette(start=0.5, rot=-0.45, dark=0.1, light=.6, gamma=0.95, reverse=False, hue=0.9,as_cmap=True)\n",
    "\n",
    "# Add color by CAGR\n",
    "hue=\"Specialty\"\n",
    "plot_df = plot_df[plot_df[hue].isin(order)]\n",
    "plot_df[\"CAGR\"] = plot_df[hue].map(cagr_df[\"CAGR (%)\"])\n",
    "\n",
    "# use same min/max values as previous for same scale ridge plots\n",
    "g = ridge_plot(plot_df, hue=hue, order=order, pal=pal, vmin=vmin, vmax=vmax)\n",
    "g.figure.savefig(\"./output/figures/Figure3B.pdf\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4: LDA groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from utils.ClinicalNoteLDA import ClinicalNoteLDA\n",
    "\n",
    "### Do topic modeling for each type of digital health term\n",
    "# Load data\n",
    "dh_terms_df = pd.DataFrame()\n",
    "dh_term_files = glob.glob(\"./output/dhnotes/sentences/*.parquet.gzip\")\n",
    "dh_terms_clean = list(terms[\"Term_clean\"])\n",
    "\n",
    "# get all sentences from all patients\n",
    "# sent_extended means each digital health sentence + sentence before and sentence after\n",
    "for file in dh_term_files:\n",
    "    term_df = pd.read_parquet(file)\n",
    "    term_df[\"note_text_dh_sent\"] = term_df[\"note_text_dh_sent\"].apply(lambda x: \" \".join(x))\n",
    "    term_df[\"note_text_dh_sent_extended\"] = term_df[\"note_text_dh_sent_extended\"].apply(lambda x: \" \".join(x))\n",
    "    dh_terms_df = pd.concat([dh_terms_df, term_df])\n",
    "    \n",
    "# Get all sentences from each note\n",
    "dh_term_sentences = dh_terms_df.groupby(\"note_id\")[\"note_text_dh_sent\"].sum()\n",
    "notes_df[\"sentences\"] = notes_df[\"note_id\"].map(dh_term_sentences)\n",
    "\n",
    "dh_terms_df = notes_df.dropna(subset=\"sentences\")\n",
    "dh_terms_df[\"All\"] = True\n",
    "'''\n",
    "# Coherence metrics for topic selection\n",
    "figure_name = \"Figure4\"\n",
    "category=\"All\"\n",
    "\n",
    "dh_subset_df = dh_terms_df[dh_terms_df[category]]\n",
    "\n",
    "med_lda = ClinicalNoteLDA(list(dh_subset_df[\"sentences\"]))\n",
    "custom_stopwords = [\"ug\", \"mg\",\"kg\", \"ml\", \"year\", \"years\", \"month\", \"months\", \"day\", \"days\"]\n",
    "med_lda.preprocessDHNotes(custom_stopwords=custom_stopwords)\n",
    "\n",
    "# Grid search - Done\n",
    "grid_search = {\"num_topics\":[10,11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 45, 50]}\n",
    "coherence_df = med_lda.hparam_sweep(grid_search, no_below=5, no_above=0.5, coherence=\"c_npmi\")\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = sns.scatterplot(data=coherence_df,  y=0, x=\"index\") \n",
    "\n",
    "# Save coherence figure and raw data\n",
    "ax.figure.savefig(f\"./output/figures/supplement/{figure_name}Data_coherence.pdf\", bbox_inches='tight')\n",
    "coherence_df.to_csv(f\"./output/figures/supplement/{figure_name}Data_coherence.csv\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''figures_dict = {\"Figure4A\":\"Connected_digital_product\",\n",
    "                \"Figure4B\":\"Generic_software_intervention\",\n",
    "                \"FigureS4A\":\"Single_intervention\",\n",
    "                \"FigureS4B\":\"Other\"}\n",
    "\n",
    "### Figure 4A, 4B, 4SA, 4SB: LDA coherence scores for each category\n",
    "for figure_name in figures_dict:\n",
    "    category = figures_dict[figure_name]\n",
    "    dh_subset_df = dh_terms_df[dh_terms_df[category]]\n",
    "\n",
    "    med_lda = ClinicalNoteLDA(list(dh_subset_df[\"sentences\"]))\n",
    "    med_lda.preprocessDHNotes()\n",
    "\n",
    "    # Grid search - Done\n",
    "    grid_search = {\"num_topics\":[10,11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]} # 10 is best with no_below=5, no_above=0.5\n",
    "    coherence_df = med_lda.hparam_sweep(grid_search, no_below=5, no_above=0.5, coherence=\"c_npmi\")\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax = sns.scatterplot(data=coherence_df,  y=0, x=\"index\") \n",
    "\n",
    "    # Save coherence figure and raw data\n",
    "    ax.figure.savefig(f\"./output/figures/supplement/{figure_name}Data_coherence.pdf\", bbox_inches='tight')\n",
    "    coherence_df.to_csv(f\"./output/figures/supplement/{figure_name}Data_coherence.csv\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "'''figures_dict = {\"Figure4A\":\"Connected_digital_product\",\n",
    "                \"Figure4B\":\"Generic_software_intervention\",\n",
    "                \"FigureS4A\":\"Single_intervention\",\n",
    "                \"FigureS4B\":\"Other\"}\n",
    "'''\n",
    "figures_dict = {\"Figure4\":\"All\"}\n",
    "\n",
    "### Figure 4A, 4B, 4SA, 4SB: Best LDA topics for each category\n",
    "### Separating out this for loop so the previous cell does not have to be rerun\n",
    "for figure_name in figures_dict:\n",
    "    category = figures_dict[figure_name]\n",
    "    dh_subset_df = dh_terms_df[dh_terms_df[category]]\n",
    "\n",
    "    med_lda = ClinicalNoteLDA(list(dh_subset_df[\"sentences\"]))\n",
    "    med_lda.preprocessDHNotes()\n",
    "    \n",
    "    # Get best number of notes (highest coherence score)\n",
    "    best_df = pd.read_csv(f\"./output/figures/supplement/{figure_name}Data_coherence.csv\", index_col=0)\n",
    "    best_df = best_df.sort_values(\"0\", ascending=False)\n",
    "    best_k = best_df.iloc[0][\"index\"]\n",
    "    \n",
    "    # Create final LDA\n",
    "    med_lda.create_lda(no_below=5, no_above=0.5, num_topics=best_k, coherence='c_npmi') #c_uci\n",
    "    vis = med_lda.visualize_lda()\n",
    "    \n",
    "    # Get top topics as scatterplot\n",
    "    supplement= \"/supplement\" if \"FigureS\" in figure_name else \"\"\n",
    "    #axis = (-0.4,0.4) if if \"FigureS\" in figure_name else (-0.3,0.3) # TODO: fix the axis\n",
    "    # ) for all\n",
    "    \n",
    "    fig = ClinicalNoteLDA.scatterplot_topics(vis, x_axis_lim=[-0.42, 0.24],y_axis_lim=[-0.3, 0.25],)\n",
    "    fig.figure.savefig(f\"./output/figures{supplement}/{figure_name}_Scatter.pdf\", bbox_inches='tight')\n",
    "  \n",
    "    # Get top words as barplot\n",
    "    #fig = ClinicalNoteLDA.barplot_top_terms(vis, normalize=True)\n",
    "    #fig.figure.savefig(f\"./DHinRWD/dataOutput{supplement}/{figure_name}_bar.pdf\", bbox_inches='tight')\n",
    "    \n",
    "    # print top words in topic \n",
    "    #med_lda.lda_model.print_topics(num_words=10)\n",
    "\n",
    "    # Get top 10 terms in each topic\n",
    "    topics_df = pd.DataFrame(med_lda.lda_model.show_topics(formatted=False,num_topics=-1))\n",
    "    topics_df[\"topics\"] = [\",\".join([t[0] for t in terms]) for terms in topics_df[1]]\n",
    "    topics_df[\"freq\"] = [[t[1] for t in terms] for terms in topics_df[1]]\n",
    "    topics_df = topics_df.iloc[:, [0,2,3]]\n",
    "    topics_df.columns = [\"unsorted_topic_num\", \"Top terms\", \"Frequency\"]\n",
    "\n",
    "    # Assign each note to a topic and add counts\n",
    "    get_document_topics = [med_lda.lda_model.get_document_topics(item) for item in med_lda.corpus]\n",
    "\n",
    "    dh_subset_df[\"topic\"]= [i[0][0] if len(i)==1 else ClinicalNoteLDA.get_top_topic(i)[0] for i in get_document_topics]\n",
    "    dh_subset_df[\"probs\"]= [i[0][1] if len(i)==1 else ClinicalNoteLDA.get_top_topic(i)[1] for i in get_document_topics]\n",
    "\n",
    "    # Supplemental figure: Save probability distribution of topics\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax = sns.histplot(dh_subset_df[\"probs\"])\n",
    "    ax.set(xlabel=\"Probability\")\n",
    "\n",
    "    supplement= \"/supplement\" if \"FigureS\" in figure_name else \"/raw\"\n",
    "    ax.figure.savefig(f\"./output/figures/supplement/{figure_name}_TopicDistribution.pdf\", bbox_inches='tight')\n",
    "\n",
    "    # Raw data: Add counts of each topic to top terms dataframe & save\n",
    "    topics_df[\"Document counts\"] = topics_df[\"unsorted_topic_num\"].map(dh_subset_df.value_counts(\"topic\"))\n",
    "    \n",
    "    # Map sorted topic numbers from pyLDAvis (sorts by default) to original topics\n",
    "    topic_values_df = vis.topic_info.copy(deep=True) \n",
    "    topic_values_df = topic_values_df.sort_values(\"Freq\", ascending=False).groupby(\"Category\").head(10)\n",
    "    topic_values_df[\"Sum\"] = topic_values_df.groupby(\"Category\")[\"Freq\"].transform('sum')\n",
    "    topic_values_df[\"Frequency\"] = topic_values_df[\"Freq\"] / topic_values_df[\"Sum\"]\n",
    "    topic_values_df = pd.DataFrame(topic_values_df.groupby(\"Category\")[\"Term\"].apply(lambda x: \",\".join(x)))\n",
    "    topics_df[\"sorted_topic\"] = topics_df[\"Top terms\"].map(dict(zip(topic_values_df[\"Term\"], topic_values_df.index)))\n",
    "\n",
    "    topics_df[\"sorted_topic_num\"] = [int(t.split(\"Topic\")[1]) if \"Topic\" in t else t for t in topics_df[\"sorted_topic\"]]\n",
    "    topics_df = topics_df.sort_values(\"Document counts\", ascending=False)\n",
    "\n",
    "    supplement= \"/supplement\" if \"FigureS\" in figure_name else \"\"\n",
    "    topics_df.to_csv(f\"./output/figures{supplement}/{figure_name}Topics.csv\")\n",
    "    \n",
    "    # Save topics\n",
    "    dh_subset_df[\"sorted_topic_num\"] = dh_subset_df[\"topic\"].map(dict(zip(topics_df[\"unsorted_topic_num\"], topics_df[\"sorted_topic_num\"])))\n",
    "    topic_distribution = dh_subset_df[[\"note_id\", \"patientid\", \"sentences\", \"topic\" ,\"sorted_topic_num\", \"probs\"]]\n",
    "    topic_distribution.to_parquet(f\"./output/dhnotes/{figure_name}DHnotes_topics.parquet.gzip\", compression=\"gzip\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4B\n",
    "term_freq = pd.read_csv(\"./output/figures/Figure4Topics.csv\", index_col=0)\n",
    "term_freq[\"Term\"] = [t.split(\",\") for t in term_freq[\"Top terms\"]]\n",
    "term_freq[\"Frequency\"] = [t.strip(\"[]\").split(\", \") for t in term_freq[\"Frequency\"]]\n",
    "term_freq[\"Frequency\"] = [[float(f) for f in t] for t in term_freq[\"Frequency\"]]\n",
    "term_freq = term_freq.explode([\"Term\", \"Frequency\"])\n",
    "term_freq = term_freq[[\"sorted_topic\", \"Term\", \"Frequency\", \"Document counts\"]]\n",
    "\n",
    "# Get top topics by document counts to plot\n",
    "top_topics = term_freq.groupby(\"sorted_topic\").first().sort_values(\"Document counts\")\n",
    "plot_df = term_freq[term_freq[\"sorted_topic\"].isin(top_topics.iloc[-10:].index)]\n",
    "\n",
    "g = sns.catplot(data=plot_df, x=\"Frequency\", y=\"Term\", col=\"sorted_topic\",\n",
    "                         kind=\"bar\", height=6, aspect=0.7, col_wrap=5, \n",
    "                         sharey=False, sharex=False, facet_kws=dict(margin_titles=True), )\n",
    "\n",
    "g.figure.subplots_adjust(wspace=.55, hspace=.2)\n",
    "g.set_titles(template=\"{col_name}\")\n",
    "g.figure.savefig(f\"./output/figures/Figure4B.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Figure 4B\n",
    "term_freq = pd.read_csv(\"./output/figures/Figure4Topics.csv\", index_col=0)\n",
    "term_freq[\"Term\"] = [t.split(\",\") for t in term_freq[\"Top terms\"]]\n",
    "term_freq[\"Frequency\"] = [t.strip(\"[]\").split(\", \") for t in term_freq[\"Frequency\"]]\n",
    "term_freq[\"Frequency\"] = [[float(f) for f in t] for t in term_freq[\"Frequency\"]]\n",
    "term_freq = term_freq.explode([\"Term\", \"Frequency\"])\n",
    "term_freq = term_freq[[\"sorted_topic\", \"Term\", \"Frequency\", \"Document counts\"]]\n",
    "\n",
    "# Get top topics by document counts to plot\n",
    "top_topics = term_freq.groupby(\"sorted_topic\").first().sort_values(\"Document counts\")\n",
    "plot_df = term_freq[term_freq[\"sorted_topic\"].isin(top_topics.iloc[:-10].index)]\n",
    "\n",
    "g = sns.catplot(data=plot_df, x=\"Frequency\", y=\"Term\", col=\"sorted_topic\",\n",
    "                         kind=\"bar\", height=6, aspect=0.7, col_wrap=5, \n",
    "                         sharey=False, sharex=False, facet_kws=dict(margin_titles=True), )\n",
    "\n",
    "g.figure.subplots_adjust(wspace=.55, hspace=.2)\n",
    "g.set_titles(template=\"{col_name}\")\n",
    "g.figure.savefig(f\"./output/figures/supplement/FigureS4A.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
